#coding=utf-8
import os
import xlwt
from lxml import etree
import requests
import StringIO
import time
global wb_data
wb_data=[]

def get_total_page_number(html):
    page = etree.HTML(html.lower())
    total_page=page.xpath(u'//*[@id="block-content-article"]/div[2]/div[13]/span')
    total=total_page[0]
    i=str(total.text.split('/')[1].encode('utf-8'))
    i=i[0:len(i)-3]
    return int(i)

def get_articles_info(html,wb_data):
    page = etree.HTML(html.lower())
    #加载文章标题
    articles=page.xpath(u'//*[@id="block-content-article"]/div[2]/div/a[2][@class="title"]')
    articles=articles[0:len(articles)]
    articles_info=[]
    for article in articles:
        articles_info.append(article.text)
    #加载文章发表时间
    times=page.xpath(u'//*[@id="block-content-article"]/div[2]/div/a[2]')
    times=articles[0:len(times)]

    date_info=[]
    times_info=[]
    for time in times:
        temp=str(time.attrib['title'].encode('utf-8')).split(' ')
        date_info.append(temp[1])
        times_info.append(temp[2])
    #加载文章评论数
    comments_number=page.xpath(u'//*[@id="block-content-article"]/div[2]/div/p/span[1]')
    comments_info=[]
    for comment in comments_number:
        comments_info.append(comment.text)
    #加载文章围观数    
    view_number=page.xpath(u'//*[@id="block-content-article"]/div[2]/div/p/span[2]')
    views_info=[]
    for view in view_number:
        views_info.append(view.text)
    for per_data in zip(articles_info,date_info,times_info,comments_info,views_info):
        wb_data.append(per_data)

def save_data_excel(wb_data):
    f = xlwt.Workbook()
    sheet1 = f.add_sheet(u'sheet1',cell_overwrite_ok=True)
    row0=[u'title',u'date',u'time',u'comments',u'views']
    for i in range(0,len(row0)):
        sheet1.write(0,i,row0[i])
    for i in range(0,len(wb_data)-1):
        sheet1.write(i+1,0,wb_data[i][0])
        sheet1.write(i+1,1,wb_data[i][1])
        sheet1.write(i+1,2,wb_data[i][2])
        sheet1.write(i+1,3,wb_data[i][3])
        sheet1.write(i+1,4,wb_data[i][4])
    f.save('D:\\ACFUN.xls')#save file


if __name__=='__main__':
    url1='http://www.acfun.tv/v/list73/index_'
    url2='.htm'
    start_url=url1+'_1'+url2
    s=requests.get(start_url)
    html=s.text.encode('utf-8')

    total_page_number=get_total_page_number(html)
    print total_page_number,type(total_page_number)
    number=range(1,total_page_number)
    for i in number:
        s=requests.get(url1+str(i)+url2)
        html=s.text.encode('utf-8')
        get_articles_info(html,wb_data)
        time.sleep(2)
        print '第{}页已经爬完'.format(i)
    save_data_excel(wb_data)
   


